{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d93c61-70e3-4a4c-953d-59bf359d9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from DQN_Utils import make_env, DQNAgent\n",
    "import torch as T\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac5e811-7b97-4cfb-aace-58ebd412409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", continuous=False, render_mode='rgb_array')\n",
    "env = make_env(env)\n",
    "agent = DQNAgent(gamma=0.99, epsilon=1.0, learning_rate=2.5e-4,\n",
    "                 input_shape=(env.observation_space.shape),\n",
    "                 n_actions=env.action_space.n,\n",
    "                 memory_size=1)\n",
    "agent.Qeval_Network.load_state_dict(T.load('checkpoints/Qeval_Network.pt', map_location=agent.Qeval_Network.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c522ebc8-44bc-4d31-a45f-be1c1d673b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward: 592.62\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "done = False\n",
    "max_steps = 1000\n",
    "step = 0\n",
    "episode_reward = 0\n",
    "s = env.reset()\n",
    "while not done and step < max_steps:\n",
    "    frames.append(env.render())\n",
    "    s = T.tensor(np.array([s]), dtype=T.float).to(agent.Qeval_Network.device)\n",
    "    Qvalues = agent.Qeval_Network.forward(s).detach()\n",
    "    action = T.argmax(Qvalues).item()\n",
    "    s, r, done, _, _ = env.step(action)\n",
    "    episode_reward += r\n",
    "    step+=1\n",
    "print(f'Episode Reward: {episode_reward:.2f}')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b940f565-7b32-41a6-8554-dacc8bd72e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_writer = cv2.VideoWriter('CarRacing.webm', cv2.VideoWriter_fourcc('V', 'P', '9', '0'), 10, (600, 400))\n",
    "for frame in frames:\n",
    "    video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "video_writer.release()\n",
    "del frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0d6e8-0384-4f00-8c92-f8a20483db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_logs = pd.read_csv('CarRacing_DQN_training_logs.csv')\n",
    "training_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dd166-5b24-454f-adc4-dfd5185e17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Steps')\n",
    "ax1.set_ylabel('Reward')\n",
    "\n",
    "plot1, = ax1.plot(training_logs['step'], training_logs['50-ep-avg-reward'], color='#bf1000', label='50-Episode Avg Reward')\n",
    "plot2, = ax1.plot(training_logs['step'], training_logs['best-so-far'], color='#0430bf', label='Best so Far')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Epsilon', color='#087d04')\n",
    "plot3, = ax2.plot(training_logs['step'], training_logs['epsilon'], color='#087d04', label='Epsilon', alpha=0.4)\n",
    "\n",
    "plots = [plot1, plot2, plot3]\n",
    "labels = [plot.get_label() for plot in plots]\n",
    "\n",
    "ax1.set_yticks([0, 200, 400, 600, 800, 1000])\n",
    "ax1.set_ylim([-100, 1100])\n",
    "ax2.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax2.set_ylim([-0.1, 1.1])\n",
    "\n",
    "ax1.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "ax1.xaxis.major.formatter._useMathText = True\n",
    "\n",
    "ax1.grid()\n",
    "\n",
    "plt.legend(plots, labels, bbox_to_anchor=(1.2, 0.5), loc='center left')\n",
    "plt.subplots_adjust(right=0.8)\n",
    "plt.title('Learning Convergence')\n",
    "plt.savefig('learning-plot.jpg', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
